{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Sessions Script\n",
    "\n",
    "This script is used to merge two or more sessions, provided they do not contain overlapping regions of interest (ROIs).\n",
    "\n",
    "### Prerequisites:\n",
    "- Paths to two session directories with extracted shorelines.\n",
    "- The desired name for the merged session directory that will be saved in the `sessions` directory.\n",
    "\n",
    "### Optional:\n",
    "- A `config.json` file with transect settings for calculating shoreline-transect intersections.\n",
    "\n",
    "### Instructions:\n",
    "1. Enter the paths to the session directories below:\n",
    "    ``` python\n",
    "   session_locations=[\n",
    "       '<path_to_first_session_directory>',\n",
    "       '<path_to_second_session_directory>'\n",
    "      ]\n",
    "    ```\n",
    "   Example:\n",
    "   - Notice that because these are Windows locations we put `r` at the beginning of each location\n",
    "    ``` python\n",
    "   session_locations=[\n",
    "      r'C:\\development\\doodleverse\\coastseg\\CoastSeg\\sessions\\es1\\ID_13_datetime06-05-23__04_16_45',\n",
    "      r'C:\\development\\doodleverse\\coastseg\\CoastSeg\\sessions\\es1\\ID_12_datetime06-05-23__04_16_45'\n",
    "      ]\n",
    "    ```\n",
    "2. Specify the name for the merged session directory:\n",
    "   - `merged_session_directory`: `\"<name_of_merged_session_directory>\"`\n",
    "\n",
    "3. (Optional) If you want to use your own advanced settings in a `config.json` file, include its path:\n",
    "   - `config_file`: `\"<path_to_config_json>\"`\n",
    "\n",
    "With the above information, the script can be executed to merge the specified sessions into a single session directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_locations=[r'C:\\development\\doodleverse\\coastseg\\CoastSeg\\sessions\\es1\\ID_13_datetime06-05-23__04_16_45',\n",
    "                   r'C:\\development\\doodleverse\\coastseg\\CoastSeg\\sessions\\es1\\ID_12_datetime06-05-23__04_16_45']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_session_directory='merged_session_test1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\development\\doodleverse\\coastseg\\CoastSeg\\sessions\n",
      "Merged session will be saved to c:\\development\\doodleverse\\coastseg\\CoastSeg\\sessions\\merged_session_test1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# enter the location of your sessions directory if this is not correct\n",
    "sessions_directory = os.path.join(os.getcwd(), 'sessions')\n",
    "print(sessions_directory)\n",
    "merged_session_location = os.path.join(sessions_directory, merged_session_directory)\n",
    "os.makedirs(merged_session_location, exist_ok=True)\n",
    "\n",
    "print(f\"Merged session will be saved to {merged_session_location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shoreline-Transect Intersection Analysis Settings\n",
    "\n",
    "The default settings listed below should suffice for most use cases to find where extracted shorelines intersect transects. However, if you modified the advanced settings then you will need to adjust the settings.\n",
    "\n",
    "\n",
    "Most users will want to just use the default settings listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_transects ={\n",
    "            \"along_dist\": 25,  # along-shore distance to use for computing the intersection\n",
    "            \"min_points\": 3,  # minimum number of shoreline points to calculate an intersection\n",
    "            \"max_std\": 15,  # max std for points around transect\n",
    "            \"max_range\": 30,  # max range for points around transect\n",
    "            \"min_chainage\": -100,  # largest negative value along transect (landwards of transect origin)\n",
    "            \"multiple_inter\": \"auto\",  # mode for removing outliers ('auto', 'nan', 'max')\n",
    "            \"prc_multiple\": 0.1,  # percentage of the time that multiple intersects are present to use the max\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "from typing import List, Union\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import LineString, MultiLineString, MultiPoint\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "from coastseg import geodata_processing\n",
    "from coastseg.file_utilities import to_file\n",
    "from coastseg.common import get_cross_distance_df\n",
    "from coastseg.common import convert_linestrings_to_multipoints, stringify_datetime_columns\n",
    "from coastsat import SDS_transects\n",
    "\n",
    "def convert_multipoints_to_linestrings(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Convert MultiPoint geometries in a GeoDataFrame to LineString geometries.\n",
    "\n",
    "    Args:\n",
    "    - gdf (gpd.GeoDataFrame): The input GeoDataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - gpd.GeoDataFrame: A new GeoDataFrame with LineString geometries. If the input GeoDataFrame\n",
    "                        already contains LineStrings, the original GeoDataFrame is returned.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a copy of the GeoDataFrame\n",
    "    gdf_copy = gdf.copy()\n",
    "\n",
    "    # Check if all geometries in the gdf are LineStrings\n",
    "    if all(gdf_copy.geometry.type == \"LineString\"):\n",
    "        return gdf_copy\n",
    "\n",
    "    def multipoint_to_linestring(multipoint):\n",
    "        if isinstance(multipoint, MultiPoint):\n",
    "            return LineString(multipoint.geoms)\n",
    "        return multipoint\n",
    "\n",
    "    # Convert each MultiPoint to a LineString\n",
    "    gdf_copy[\"geometry\"] = gdf_copy[\"geometry\"].apply(multipoint_to_linestring)\n",
    "\n",
    "    return gdf_copy\n",
    "\n",
    "def dataframe_to_dict(df: pd.DataFrame, key_map: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Converts a DataFrame to a dictionary, with specific mapping between dictionary keys and DataFrame columns.\n",
    "\n",
    "    Parameters:\n",
    "    df : DataFrame\n",
    "        The DataFrame to convert.\n",
    "    key_map : dict\n",
    "        A dictionary where keys are the desired dictionary keys and values are the corresponding DataFrame column names.\n",
    "\n",
    "    Returns:\n",
    "    dict\n",
    "        The resulting dictionary.\n",
    "    \"\"\"\n",
    "    result_dict = defaultdict(list)\n",
    "\n",
    "    for dict_key, df_key in key_map.items():\n",
    "        if df_key in df.columns:\n",
    "            if df_key == 'date':\n",
    "                # Assumes the column to be converted to date is the one specified in the mapping with key 'date'\n",
    "                result_dict[dict_key] = list(df[df_key].apply(lambda x: x.strftime(\"%Y-%m-%d %H:%M:%S\") if pd.notnull(x) else None))\n",
    "            elif df_key == 'geometry':\n",
    "                # Assumes the column to be converted to geometry is the one specified in the mapping with key 'geometry'\n",
    "                result_dict[dict_key] = list(df[df_key].apply(lambda x: np.array([list(point.coords[0]) for point in x.geoms]) if pd.notnull(x) else None))\n",
    "            else:\n",
    "                result_dict[dict_key] = list(df[df_key])\n",
    "    \n",
    "    return dict(result_dict)\n",
    "\n",
    "def convert_lines_to_multipoints(gdf):\n",
    "    # Create a copy of the input GeoDataFrame to avoid modifying it in place\n",
    "    gdf = gdf.copy()\n",
    "\n",
    "    # Define a function to convert LineString or MultiLineString to MultiPoint\n",
    "    def line_to_multipoint(geometry):\n",
    "        if isinstance(geometry, LineString):\n",
    "            return MultiPoint(geometry.coords)\n",
    "        elif isinstance(geometry, MultiLineString):\n",
    "            points = [MultiPoint(line.coords) for line in geometry]\n",
    "            return MultiPoint([point for multi in points for point in multi])\n",
    "        else:\n",
    "            return geometry  # Return the original geometry if it's not a LineString or MultiLineString\n",
    "\n",
    "    # Apply the conversion function to each row in the GeoDataFrame\n",
    "    gdf['geometry'] = gdf['geometry'].apply(line_to_multipoint)\n",
    "\n",
    "    return gdf\n",
    "\n",
    "def merge_geodataframes(on, how='inner', aggregation_funcs=None,crs='epsg:4326', *gdfs):\n",
    "    \"\"\"\n",
    "    Merges multiple GeoDataFrames based on a common column.\n",
    "    \n",
    "    Parameters:\n",
    "    on : str or list of str\n",
    "        Column name or list of column names to merge on.\n",
    "    how : str, optional\n",
    "        Type of merge to be performed (default is 'inner').\n",
    "    aggregation_funcs : dict, optional\n",
    "        Dictionary of column names to aggregation functions.\n",
    "        Example: for the columns 'cloud_cover' and 'geoaccuracy', the mean aggregation function can be specified as:\n",
    "        aggregation_funcs = {\n",
    "            'cloud_cover': 'mean',\n",
    "            'geoaccuracy': 'mean'\n",
    "        }\n",
    "    *gdfs : GeoDataFrames\n",
    "        Variable number of GeoDataFrames to be merged.\n",
    "        \n",
    "    Returns:\n",
    "    GeoDataFrame\n",
    "        The merged GeoDataFrame with aggregated columns as specified.\n",
    "    \"\"\"\n",
    "    if len(gdfs) < 2:\n",
    "        raise ValueError(\"At least two GeoDataFrames must be provided for merging\")\n",
    "\n",
    "    # Set default aggregation functions if none are provided\n",
    "    if aggregation_funcs is None:\n",
    "        aggregation_funcs = {}\n",
    "        \n",
    "    # Perform the merge while applying the custom aggregation functions\n",
    "    merged_gdf = gdfs[0]\n",
    "    merged_gdf.set_crs(crs)\n",
    "    for gdf in gdfs[1:]:\n",
    "        merged_gdf = pd.merge(merged_gdf, gdf, on=on, how=how, suffixes=('_left', '_right'))\n",
    "\n",
    "        # Apply aggregation functions\n",
    "        for col, func in aggregation_funcs.items():\n",
    "            col_left = f'{col}_left'\n",
    "            col_right = f'{col}_right'\n",
    "\n",
    "            # Check if the columns exist in both GeoDataFrames\n",
    "            if col_left in merged_gdf.columns and col_right in merged_gdf.columns:\n",
    "                # Apply the aggregation function and drop the original columns\n",
    "                merged_gdf[col] = merged_gdf[[col_left, col_right]].agg(func, axis=1)\n",
    "                merged_gdf = merged_gdf.drop(columns=[col_left, col_right])\n",
    "                \n",
    "    return merged_gdf\n",
    "\n",
    "def read_first_geojson_file(directory:str,filenames=['extracted_shorelines_lines.geojson', 'extracted_shorelines.geojson']):\n",
    "    # Loop over the filenames\n",
    "    for filename in filenames:\n",
    "        filepath = os.path.join(directory, filename)\n",
    "\n",
    "        # If the file exists, read it and return the GeoDataFrame\n",
    "        if os.path.exists(filepath):\n",
    "            return geodata_processing.read_gpd_file(filepath)\n",
    "\n",
    "    # If none of the files exist, raise an exception\n",
    "    raise FileNotFoundError(f\"None of the files {filenames} exist in the directory {directory}\")\n",
    "\n",
    "def clip_gdfs(gdfs, overlap_gdf):\n",
    "    \"\"\"\n",
    "    Clips GeoDataFrames to an overlapping region.\n",
    "\n",
    "    Parameters:\n",
    "    gdfs : list of GeoDataFrames\n",
    "        The GeoDataFrames to be clipped.\n",
    "    overlap_gdf : GeoDataFrame\n",
    "        The overlapping region to which the GeoDataFrames will be clipped.\n",
    "\n",
    "    Returns:\n",
    "    list of GeoDataFrames\n",
    "        The clipped GeoDataFrames.\n",
    "    \"\"\"\n",
    "    clipped_gdfs = []\n",
    "    for gdf in gdfs:\n",
    "        clipped_gdf = gpd.clip(gdf, overlap_gdf)\n",
    "        if not clipped_gdf.empty:\n",
    "            clipped_gdfs.append(clipped_gdf)\n",
    "            clipped_gdf.plot()\n",
    "    return clipped_gdfs\n",
    "\n",
    "def calculate_overlap(gdf):\n",
    "    # Check if the input GeoDataFrame is empty\n",
    "    if not hasattr(gdf,'empty'):\n",
    "        return gpd.GeoDataFrame()\n",
    "    if gdf.empty:\n",
    "        if hasattr(gdf,'crs'):\n",
    "            return gpd.GeoDataFrame(crs=gdf.crs)\n",
    "        else:\n",
    "            return gpd.GeoDataFrame()\n",
    "    \n",
    "    # Initialize an empty list to store the results\n",
    "    overlap_list = []\n",
    "    \n",
    "    # Loop over each pair of rows in gdf\n",
    "    for i in range(len(gdf)):\n",
    "        for j in range(i+1, len(gdf)):\n",
    "            # Check for intersection\n",
    "            if gdf.iloc[i].geometry.intersects(gdf.iloc[j].geometry):\n",
    "                # Calculate the intersection\n",
    "                intersection = gdf.iloc[i].geometry.intersection(gdf.iloc[j].geometry)\n",
    "                \n",
    "                # Create a new row with the intersection and append to the result list\n",
    "                overlap_list.append({'geometry': intersection})\n",
    "    \n",
    "    # Create a DataFrame from the results list\n",
    "    overlap_df = pd.DataFrame(overlap_list)\n",
    "    \n",
    "    # Convert the result DataFrame to a GeoDataFrame and set the CRS\n",
    "    overlap_gdf = gpd.GeoDataFrame(overlap_df, geometry='geometry', crs=gdf.crs)\n",
    "    \n",
    "    return overlap_gdf\n",
    "\n",
    "def average_multipoints(multipoints)->MultiPoint:\n",
    "    \"\"\"\n",
    "    Calculate the average MultiPoint geometry from a list of MultiPoint geometries.\n",
    "    \n",
    "    This function takes a list of shapely MultiPoint geometries, ensures they all have the same number of points\n",
    "    by padding shorter MultiPoints with their last point, and then calculates the average coordinates\n",
    "    for each point position across all the input MultiPoint geometries. \n",
    "    \n",
    "    The result is a new MultiPoint geometry that represents the average shape of the input MultiPoints.\n",
    "    \n",
    "    Parameters:\n",
    "    multipoints (list of shapely.geometry.MultiPoint): A list of shapely MultiPoint geometries to be averaged.\n",
    "    \n",
    "    Returns:\n",
    "    shapely.geometry.MultiPoint: A MultiPoint geometry representing the average shape of the input MultiPoints.\n",
    "    \n",
    "    Raises:\n",
    "    ValueError: If the input list of MultiPoint geometries is empty.\n",
    "    \n",
    "    Example:\n",
    "    >>> from shapely.geometry import MultiPoint\n",
    "    >>> multipoint1 = MultiPoint([(0, 0), (1, 1), (2, 2)])\n",
    "    >>> multipoint2 = MultiPoint([(1, 1), (2, 2)])\n",
    "    >>> multipoint3 = MultiPoint([(0, 0), (1, 1), (2, 2), (3, 3)])\n",
    "    >>> average_mp = average_multipoints([multipoint1, multipoint2, multipoint3])\n",
    "    >>> print(average_mp)\n",
    "    MULTIPOINT (0.3333333333333333 0.3333333333333333, 1.3333333333333333 1.3333333333333333, 2 2, 3 3)\n",
    "    \"\"\"\n",
    "    if not multipoints:\n",
    "        raise ValueError(\"The list of MultiPoint geometries is empty\")\n",
    "    \n",
    "    # Find the maximum number of points in any MultiPoint\n",
    "    max_len = max(len(mp.geoms) for mp in multipoints)\n",
    "    \n",
    "    # Pad shorter MultiPoints with their last point\n",
    "    padded_multipoints = []\n",
    "    for mp in multipoints:\n",
    "        if len(mp.geoms) < max_len:\n",
    "            padded_multipoints.append(MultiPoint(list(mp.geoms) + [mp.geoms[-1]] * (max_len - len(mp.geoms))))\n",
    "        else:\n",
    "            padded_multipoints.append(mp)\n",
    "            \n",
    "    # Calculate the average coordinates for each point\n",
    "    num_multipoints = len(padded_multipoints)\n",
    "    average_coords = []\n",
    "    for i in range(max_len):\n",
    "        avg_left = sum(mp.geoms[i].x for mp in padded_multipoints) / num_multipoints\n",
    "        avg_right = sum(mp.geoms[i].y for mp in padded_multipoints) / num_multipoints\n",
    "        average_coords.append((avg_left, avg_right))\n",
    "        \n",
    "    return MultiPoint(average_coords)\n",
    "\n",
    "def average_columns(df, col1, col2, new_col):\n",
    "    df[new_col] = df[[col1, col2]].mean(axis=1,skipna=True)\n",
    "    return df\n",
    "\n",
    "def combine_dataframes(df1, df2, join_columns):\n",
    "    # Perform an outer join and mark the origin of each row\n",
    "    all_rows = pd.merge(df1, df2, on=join_columns, how='outer', indicator=True)\n",
    "\n",
    "    # Keep only the rows that are in 'df1' but not in 'df2'\n",
    "    df1_unique = all_rows[all_rows['_merge'] == 'left_only']\n",
    "    if 'cloud_cover_x' in df1_unique.columns and 'cloud_cover_y' in df1_unique.columns:\n",
    "        df1_unique = average_columns(df1_unique, 'cloud_cover_x', 'cloud_cover_y', 'cloud_cover')\n",
    "        df1_unique.drop(columns=['cloud_cover_x', 'cloud_cover_y'], inplace=True)\n",
    "    if 'geoaccuracy_x' in df1_unique.columns and 'geoaccuracy_y' in df1_unique.columns:\n",
    "        df1_unique = average_columns(df1_unique, 'geoaccuracy_x', 'geoaccuracy_y', 'geoaccuracy')\n",
    "        df1_unique.drop(columns=['geoaccuracy_x', 'geoaccuracy_y'], inplace=True)\n",
    "    df1_unique.drop(columns=['_merge'], inplace=True)\n",
    "    \n",
    "    # Concatenate 'df2' and the unique rows from 'df1'\n",
    "    result = pd.concat([df2, df1_unique], ignore_index=True)\n",
    "\n",
    "    def assign_geometry(row):\n",
    "        if pd.isnull(row['geometry']):\n",
    "            if pd.notnull(row['geometry_x']):\n",
    "                return row['geometry_x']\n",
    "            elif pd.notnull(row['geometry_y']):\n",
    "                return row['geometry_y']\n",
    "        else:\n",
    "            return row['geometry']\n",
    "\n",
    "    if 'geometry_x' in result.columns and 'geometry_y' in result.columns:\n",
    "        result['geometry'] = result.apply(assign_geometry, axis=1)\n",
    "        result.drop(columns=['geometry_x', 'geometry_y'], inplace=True)\n",
    "    return result\n",
    "\n",
    "def combine_geodataframes(gdf1, gdf2, join_columns, average_columns=None):\n",
    "    \"\"\"\n",
    "    Combines two GeoDataFrames, performing an outer join and averaging specified numerical columns.\n",
    "\n",
    "    Parameters:\n",
    "    gdf1, gdf2 : GeoDataFrame\n",
    "        The GeoDataFrames to combine.\n",
    "    join_columns : list of str\n",
    "        The columns to join on.\n",
    "    average_columns : list of str, optional\n",
    "        The columns to average. If None, all numerical columns with the same name in both GeoDataFrames will be averaged.\n",
    "\n",
    "    Returns:\n",
    "    GeoDataFrame\n",
    "        The combined GeoDataFrame.\n",
    "    \"\"\"\n",
    "    # Ensure that the 'geometry' column is present in both GeoDataFrames\n",
    "    if 'geometry' not in gdf1.columns or 'geometry' not in gdf2.columns:\n",
    "        raise ValueError(\"Both GeoDataFrames must have a 'geometry' column.\")\n",
    "\n",
    "    # Combine GeoDataFrames using an outer join\n",
    "    combined_gdf = pd.merge(gdf1, gdf2, on=join_columns, how='outer', suffixes=('_gdf1', '_gdf2'))\n",
    "\n",
    "    if average_columns is None:\n",
    "        # List of numerical columns to be averaged\n",
    "        average_columns = [\n",
    "            col for col in gdf1.columns\n",
    "            if col in gdf2.columns\n",
    "            and col not in join_columns + ['geometry']\n",
    "            and np.issubdtype(gdf1[col].dtype, np.number)\n",
    "            and np.issubdtype(gdf2[col].dtype, np.number)\n",
    "        ]\n",
    "\n",
    "    # Average specified numerical columns\n",
    "    for col in average_columns:\n",
    "        if f'{col}_gdf1' in combined_gdf.columns and f'{col}_gdf2' in combined_gdf.columns:\n",
    "            combined_gdf[col] = combined_gdf[[f'{col}_gdf1', f'{col}_gdf2']].mean(axis=1)\n",
    "            combined_gdf.drop(columns=[f'{col}_gdf1', f'{col}_gdf2'], inplace=True)\n",
    "\n",
    "    # Resolve geometry conflicts by prioritizing non-null values\n",
    "    combined_gdf['geometry'] = combined_gdf['geometry_gdf1'].combine_first(combined_gdf['geometry_gdf2'])\n",
    "    combined_gdf.drop(columns=['geometry_gdf1', 'geometry_gdf2'], inplace=True)\n",
    "\n",
    "    return gpd.GeoDataFrame(combined_gdf, geometry='geometry')\n",
    "\n",
    "def mergeRightUnique(left_df: gpd.GeoDataFrame, right_df:gpd.GeoDataFrame, join_columns: Union[str, List[str]] = ['date', 'satname'], CRS:str='EPSG:4326') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merges two GeoDataFrames, keeping only the unique rows from the right GeoDataFrame based on the specified join columns.\n",
    "\n",
    "    Parameters:\n",
    "    left_df : GeoDataFrame\n",
    "        The left GeoDataFrame to merge. Its CRS is set to the specified CRS if not already set.\n",
    "    right_df : GeoDataFrame\n",
    "        The right GeoDataFrame to merge. Its CRS is set to the specified CRS if not already set.\n",
    "    join_columns : str or list of str, default ['date', 'satname']\n",
    "        The columns to join on. These columns are set as the index for both GeoDataFrames. If a string is passed, it is converted to a list.\n",
    "    CRS : str, default 'EPSG:4326'\n",
    "        The Coordinate Reference System to set for the GeoDataFrames if not already set.\n",
    "\n",
    "    Returns:\n",
    "    GeoDataFrame\n",
    "        The merged GeoDataFrame, containing all rows from the left GeoDataFrame and only the unique rows from the right GeoDataFrame based on the join columns.\n",
    "    \"\"\"\n",
    "    if not left_df.crs:\n",
    "        left_df.set_crs(CRS, inplace=True)\n",
    "    if not right_df.crs:\n",
    "        right_df.set_crs(CRS, inplace=True)\n",
    "    \n",
    "    if isinstance(join_columns, str):\n",
    "        join_columns = [join_columns]\n",
    "    # Ensure that join are set as the index for both DataFrames\n",
    "    left_df.set_index(join_columns, inplace=True)\n",
    "    right_df.set_index(join_columns, inplace=True)\n",
    "\n",
    "    # Find the difference in the MultiIndex between right_df and merged_gdf\n",
    "    unique_indices = right_df.index.difference(merged_gdf.index)\n",
    "\n",
    "    # Select only those rows from right_df that have unique indices\n",
    "    unique_to_right_df = right_df.loc[unique_indices]\n",
    "    if unique_to_right_df.crs:\n",
    "        unique_to_right_df.crs = right_df.crs\n",
    "\n",
    "    # Now concatenate the merged_gdf with the unique_to_right_df\n",
    "    combined_gdf = pd.concat([merged_gdf.reset_index(), unique_to_right_df.reset_index()], ignore_index=True)\n",
    "    return combined_gdf\n",
    "\n",
    "def merge_geometries(merged_gdf, columns=None, operation=unary_union):\n",
    "    \"\"\"\n",
    "    Performs a specified operation for the geometries with the same date and satname.\n",
    "\n",
    "    Parameters:\n",
    "    merged_gdf : GeoDataFrame\n",
    "        The GeoDataFrame to perform the operation on.\n",
    "    columns : list of str, optional\n",
    "        The columns to perform the operation on. If None, all columns with 'geometry' in the name are used.\n",
    "    operation : function, optional\n",
    "        The operation to perform. If None, unary_union is used.\n",
    "\n",
    "    Returns:\n",
    "    GeoDataFrame\n",
    "        The GeoDataFrame with the operation performed.\n",
    "    \"\"\"\n",
    "    if columns is None:\n",
    "        columns = [col for col in merged_gdf.columns if 'geometry' in col]\n",
    "    else:\n",
    "        columns = [col for col in columns if col in merged_gdf.columns]\n",
    "\n",
    "    merged_gdf['geometry'] = merged_gdf[columns].apply(lambda row: operation(row.tolist()), axis=1)\n",
    "    for col in columns:\n",
    "        if col in merged_gdf.columns:\n",
    "            merged_gdf = merged_gdf.drop(columns=col)\n",
    "    return merged_gdf\n",
    "\n",
    "def merge_geojson_files(*file_paths:str, )->gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Merges any number of GeoJSON files into a single GeoDataFrame, removing any duplicate rows.\n",
    "\n",
    "    Parameters:\n",
    "    - *file_paths (str): Paths to the GeoJSON files.\n",
    "\n",
    "    Returns:\n",
    "    - GeoDataFrame: A GeoDataFrame containing the merged data from all input files, with duplicates removed.\n",
    "    \"\"\"\n",
    "    merged_gdf = gpd.GeoDataFrame()\n",
    "    for filepath in file_paths:\n",
    "        gdf = geodata_processing.read_gpd_file(filepath)\n",
    "        # Merging the two dataframes\n",
    "        merged_gdf = gpd.GeoDataFrame(pd.concat([merged_gdf, gdf], ignore_index=True))\n",
    "\n",
    "    # Dropping any duplicated rows based on all columns\n",
    "    merged_gdf_cleaned = merged_gdf.drop_duplicates()\n",
    "    return merged_gdf_cleaned\n",
    "\n",
    "def create_csv_per_transect(\n",
    "    save_path: str,\n",
    "    cross_distance_transects: dict,\n",
    "    extracted_shorelines_dict: dict,\n",
    "    roi_id: str = None,  # ROI ID is now optional and defaults to None\n",
    "    filename_suffix: str = \"_timeseries_raw.csv\",\n",
    "):\n",
    "    for key, distances in cross_distance_transects.items():\n",
    "        # Initialize the dictionary for DataFrame with mandatory keys\n",
    "        data_dict = {\n",
    "            'dates': extracted_shorelines_dict['dates'],\n",
    "            'satname': extracted_shorelines_dict['satname'],\n",
    "            key: distances\n",
    "        }\n",
    "        \n",
    "        # Add roi_id to the dictionary if provided\n",
    "        if roi_id is not None:\n",
    "            data_dict['roi_id'] = [roi_id] * len(extracted_shorelines_dict['dates'])\n",
    "\n",
    "        # Create a DataFrame directly with the data dictionary\n",
    "        df = pd.DataFrame(data_dict).set_index('dates')\n",
    "\n",
    "        # Construct the full file path\n",
    "        csv_filename = f\"{key}{filename_suffix}\"\n",
    "        fn = os.path.join(save_path, csv_filename)\n",
    "\n",
    "        # Save to CSV file, 'mode' set to 'w' for overwriting\n",
    "        try:\n",
    "            df.to_csv(fn, sep=\",\", mode='w')\n",
    "            print(f\"Time-series for transect {key} saved to {fn}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save time-series for transect {key}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all the config_gdf.geojson files together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\development\\\\doodleverse\\\\coastseg\\\\CoastSeg\\\\sessions\\\\es1\\\\ID_13_datetime06-05-23__04_16_45\\\\config_gdf.geojson', 'C:\\\\development\\\\doodleverse\\\\coastseg\\\\CoastSeg\\\\sessions\\\\es1\\\\ID_12_datetime06-05-23__04_16_45\\\\config_gdf.geojson']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>slope</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>roi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((-117.46826 33.22493, -117.46847 33.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>roi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((-117.46847 33.26526, -117.46869 33.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hxj1</td>\n",
       "      <td>shoreline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (-117.25543 32.90299, -117.25543 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hxj2</td>\n",
       "      <td>shoreline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (-117.25575 32.90568, -117.25575 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hxj3</td>\n",
       "      <td>shoreline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (-117.25804 32.91288, -117.25820 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>gpv628</td>\n",
       "      <td>transect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (-117.58446 33.38388, -117.58544 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>gpv629</td>\n",
       "      <td>transect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (-117.58550 33.38406, -117.58649 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>gpv630</td>\n",
       "      <td>transect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (-117.58670 33.38427, -117.58739 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>gpv631</td>\n",
       "      <td>transect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (-117.58746 33.38427, -117.58873 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>NaN</td>\n",
       "      <td>bbox</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((-117.61002 32.90299, -117.61002 33.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>717 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id       type  slope  \\\n",
       "0        12        roi    NaN   \n",
       "1        13        roi    NaN   \n",
       "2      hxj1  shoreline    NaN   \n",
       "3      hxj2  shoreline    NaN   \n",
       "4      hxj3  shoreline    NaN   \n",
       "..      ...        ...    ...   \n",
       "712  gpv628   transect    NaN   \n",
       "713  gpv629   transect    NaN   \n",
       "714  gpv630   transect    NaN   \n",
       "715  gpv631   transect    NaN   \n",
       "716     NaN       bbox    NaN   \n",
       "\n",
       "                                              geometry  \n",
       "0    POLYGON ((-117.46826 33.22493, -117.46847 33.2...  \n",
       "1    POLYGON ((-117.46847 33.26526, -117.46869 33.3...  \n",
       "2    LINESTRING (-117.25543 32.90299, -117.25543 32...  \n",
       "3    LINESTRING (-117.25575 32.90568, -117.25575 32...  \n",
       "4    LINESTRING (-117.25804 32.91288, -117.25820 32...  \n",
       "..                                                 ...  \n",
       "712  LINESTRING (-117.58446 33.38388, -117.58544 33...  \n",
       "713  LINESTRING (-117.58550 33.38406, -117.58649 33...  \n",
       "714  LINESTRING (-117.58670 33.38427, -117.58739 33...  \n",
       "715  LINESTRING (-117.58746 33.38427, -117.58873 33...  \n",
       "716  POLYGON ((-117.61002 32.90299, -117.61002 33.3...  \n",
       "\n",
       "[717 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from coastseg import geodata_processing\n",
    "import os\n",
    "\n",
    "# read all the config_gdfs from the session locations\n",
    "filepaths = [os.path.join(session_location, 'config_gdf.geojson') for session_location in session_locations]\n",
    "print(filepaths)\n",
    "# merge all the config_gdfs into one\n",
    "merged_config = merge_geojson_files(*filepaths)\n",
    "# optionally save the merged config_gdf \n",
    "merged_config.to_file(os.path.join(merged_session_location, 'config_gdf.geojson'), driver='GeoJSON')\n",
    "merged_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ROI Listed Below Will be Merged Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>slope</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>roi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((-117.46826 33.22493, -117.46847 33.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>roi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((-117.46847 33.26526, -117.46869 33.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id type  slope                                           geometry\n",
       "0  12  roi    NaN  POLYGON ((-117.46826 33.22493, -117.46847 33.2...\n",
       "1  13  roi    NaN  POLYGON ((-117.46847 33.26526, -117.46869 33.3..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_rows = merged_config[merged_config['type'] == 'roi']\n",
    "roi_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 2 extracted shorelines GeoDataFrames\n",
      "No overlapping ROIs found. Sessions can be merged.\n",
      "Combined 53 rows from 2 GeoDataFrames\n",
      "The following dataframe contains the combined extracted shorelines from all sessions.\n",
      " Shorelines that were extracted on the same dates have been combined.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>satname</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>geoaccuracy</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-30 18:22:25</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.088</td>\n",
       "      <td>MULTIPOINT (-117.46831 33.29341, -117.46822 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-16 18:22:17</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.802</td>\n",
       "      <td>MULTIPOINT (-117.46822 33.29345, -117.46815 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-03-20 18:22:08</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.596</td>\n",
       "      <td>MULTIPOINT (-117.46815 33.29345, -117.46805 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-08 18:22:20</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.263967</td>\n",
       "      <td>4.826</td>\n",
       "      <td>MULTIPOINT (-117.44858 33.26998, -117.44854 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-10 18:22:29</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.003838</td>\n",
       "      <td>4.275</td>\n",
       "      <td>MULTIPOINT (-117.46834 33.29332, -117.46831 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-07-26 18:22:33</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.007632</td>\n",
       "      <td>4.286</td>\n",
       "      <td>MULTIPOINT (-117.46209 33.28590, -117.46199 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-08-11 18:22:40</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.080</td>\n",
       "      <td>MULTIPOINT (-117.46831 33.29335, -117.46828 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-08-27 18:22:44</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.208</td>\n",
       "      <td>MULTIPOINT (-117.46832 33.29332, -117.46831 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-09-12 18:22:48</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.128</td>\n",
       "      <td>MULTIPOINT (-117.46829 33.29345, -117.46817 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-10-14 18:22:56</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>4.002</td>\n",
       "      <td>MULTIPOINT (-117.46154 33.28536, -117.46150 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-10-30 18:22:56</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.014848</td>\n",
       "      <td>4.851</td>\n",
       "      <td>MULTIPOINT (-117.46817 33.29345, -117.46815 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-11-15 18:22:53</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.661</td>\n",
       "      <td>MULTIPOINT (-117.46824 33.29345, -117.46815 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-12-17 18:22:50</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>5.080</td>\n",
       "      <td>MULTIPOINT (-117.46827 33.29345, -117.46815 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-01-02 18:22:45</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.318</td>\n",
       "      <td>MULTIPOINT (-117.46829 33.29345, -117.46818 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-01-18 18:22:42</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.996</td>\n",
       "      <td>MULTIPOINT (-117.46842 33.29331, -117.46833 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-03-22 18:22:20</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.147</td>\n",
       "      <td>MULTIPOINT (-117.46831 33.29345, -117.46820 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-04-23 18:22:05</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.014904</td>\n",
       "      <td>4.790</td>\n",
       "      <td>MULTIPOINT (-117.43574 33.25393, -117.43573 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-06-10 18:22:09</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.624</td>\n",
       "      <td>MULTIPOINT (-117.46831 33.29337, -117.46826 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-07-12 18:22:24</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.785</td>\n",
       "      <td>MULTIPOINT (-117.46833 33.29332, -117.46831 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-08-29 18:22:41</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>4.401</td>\n",
       "      <td>MULTIPOINT (-117.46829 33.29345, -117.46818 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-09-30 18:22:51</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.235</td>\n",
       "      <td>MULTIPOINT (-117.46822 33.29345, -117.46815 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-12-03 18:22:54</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.724</td>\n",
       "      <td>MULTIPOINT (-117.46824 33.29345, -117.46815 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-12-19 18:22:53</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.938</td>\n",
       "      <td>MULTIPOINT (-117.46822 33.29345, -117.46815 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2021-01-04 18:22:48</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.964</td>\n",
       "      <td>MULTIPOINT (-117.46824 33.29345, -117.46815 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2021-01-20 18:22:41</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.149</td>\n",
       "      <td>MULTIPOINT (-117.46845 33.29331, -117.46836 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2021-02-05 18:22:40</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.352</td>\n",
       "      <td>MULTIPOINT (-117.46831 33.29341, -117.46823 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2021-02-21 18:22:35</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.232</td>\n",
       "      <td>MULTIPOINT (-117.46831 33.29343, -117.46820 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2021-03-09 18:22:27</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.060021</td>\n",
       "      <td>5.644</td>\n",
       "      <td>MULTIPOINT (-117.46572 33.29051, -117.46569 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2021-06-13 18:22:22</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.010056</td>\n",
       "      <td>4.434</td>\n",
       "      <td>MULTIPOINT (-117.45511 33.27808, -117.45503 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2021-10-19 18:22:59</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.356</td>\n",
       "      <td>MULTIPOINT (-117.46817 33.29345, -117.46815 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2021-11-23 18:25:01</td>\n",
       "      <td>L9</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>4.860</td>\n",
       "      <td>MULTIPOINT (-117.46823 33.29345, -117.46815 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2021-12-22 18:22:51</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.106271</td>\n",
       "      <td>5.356</td>\n",
       "      <td>MULTIPOINT (-117.45486 33.27788, -117.45479 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2022-01-23 18:22:43</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.018</td>\n",
       "      <td>MULTIPOINT (-117.46831 33.29334, -117.46829 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2022-02-16 18:22:44</td>\n",
       "      <td>L9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.984</td>\n",
       "      <td>MULTIPOINT (-117.46811 33.29345, -117.46803 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2022-02-24 18:22:34</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.809</td>\n",
       "      <td>MULTIPOINT (-117.46831 33.29332, -117.46831 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2022-03-04 18:22:34</td>\n",
       "      <td>L9</td>\n",
       "      <td>0.348253</td>\n",
       "      <td>6.277</td>\n",
       "      <td>MULTIPOINT (-117.46608 33.29048, -117.46604 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2022-03-12 18:22:30</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.449</td>\n",
       "      <td>MULTIPOINT (-117.46841 33.29332, -117.46831 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2022-04-13 18:22:23</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.154</td>\n",
       "      <td>MULTIPOINT (-117.46829 33.29345, -117.46817 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2022-04-21 18:22:18</td>\n",
       "      <td>L9</td>\n",
       "      <td>0.035151</td>\n",
       "      <td>3.886</td>\n",
       "      <td>MULTIPOINT (-117.44798 33.26931, -117.44789 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2022-06-24 18:22:26</td>\n",
       "      <td>L9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.793</td>\n",
       "      <td>MULTIPOINT (-117.46831 33.29341, -117.46824 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2022-07-02 18:22:47</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.817</td>\n",
       "      <td>MULTIPOINT (-117.46823 33.29345, -117.46815 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2022-08-11 18:22:43</td>\n",
       "      <td>L9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.334</td>\n",
       "      <td>MULTIPOINT (-117.46812 33.29345, -117.46804 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2022-08-19 18:23:05</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.019461</td>\n",
       "      <td>4.262</td>\n",
       "      <td>MULTIPOINT (-117.45778 33.28118, -117.45777 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2022-08-27 18:22:47</td>\n",
       "      <td>L9</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>4.178</td>\n",
       "      <td>MULTIPOINT (-117.46284 33.28711, -117.46280 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2022-09-20 18:23:12</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.004018</td>\n",
       "      <td>3.943</td>\n",
       "      <td>MULTIPOINT (-117.46106 33.28482, -117.46102 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2022-10-22 18:23:08</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.248255</td>\n",
       "      <td>5.138</td>\n",
       "      <td>MULTIPOINT (-117.46821 33.29345, -117.46815 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2022-10-30 18:22:59</td>\n",
       "      <td>L9</td>\n",
       "      <td>0.020157</td>\n",
       "      <td>4.587</td>\n",
       "      <td>MULTIPOINT (-117.44473 33.26540, -117.44467 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2022-11-15 18:23:01</td>\n",
       "      <td>L9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.828</td>\n",
       "      <td>MULTIPOINT (-117.46825 33.29345, -117.46815 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2022-11-23 18:23:05</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.894</td>\n",
       "      <td>MULTIPOINT (-117.46810 33.29345, -117.46802 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2022-12-09 18:23:05</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.371</td>\n",
       "      <td>MULTIPOINT (-117.46810 33.29345, -117.46805 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2023-01-02 18:23:00</td>\n",
       "      <td>L9</td>\n",
       "      <td>0.059842</td>\n",
       "      <td>5.832</td>\n",
       "      <td>MULTIPOINT (-117.46823 33.29345, -117.46815 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2023-01-18 18:22:52</td>\n",
       "      <td>L9</td>\n",
       "      <td>0.149705</td>\n",
       "      <td>5.798</td>\n",
       "      <td>MULTIPOINT (-117.46223 33.28630, -117.46215 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2023-02-19 18:22:55</td>\n",
       "      <td>L9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.287</td>\n",
       "      <td>MULTIPOINT (-117.46813 33.29345, -117.46805 33...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date satname  cloud_cover  geoaccuracy  \\\n",
       "0  2018-12-30 18:22:25      L8     0.000000        5.088   \n",
       "1  2019-02-16 18:22:17      L8     0.000000        5.802   \n",
       "2  2019-03-20 18:22:08      L8     0.000000        6.596   \n",
       "3  2019-06-08 18:22:20      L8     0.263967        4.826   \n",
       "4  2019-07-10 18:22:29      L8     0.003838        4.275   \n",
       "5  2019-07-26 18:22:33      L8     0.007632        4.286   \n",
       "6  2019-08-11 18:22:40      L8     0.000000        4.080   \n",
       "7  2019-08-27 18:22:44      L8     0.000000        4.208   \n",
       "8  2019-09-12 18:22:48      L8     0.000000        4.128   \n",
       "9  2019-10-14 18:22:56      L8     0.007924        4.002   \n",
       "10 2019-10-30 18:22:56      L8     0.014848        4.851   \n",
       "11 2019-11-15 18:22:53      L8     0.000000        4.661   \n",
       "12 2019-12-17 18:22:50      L8     0.003546        5.080   \n",
       "13 2020-01-02 18:22:45      L8     0.000000        5.318   \n",
       "14 2020-01-18 18:22:42      L8     0.000000        4.996   \n",
       "15 2020-03-22 18:22:20      L8     0.000000        5.147   \n",
       "16 2020-04-23 18:22:05      L8     0.014904        4.790   \n",
       "17 2020-06-10 18:22:09      L8     0.000000        4.624   \n",
       "18 2020-07-12 18:22:24      L8     0.000000        4.785   \n",
       "19 2020-08-29 18:22:41      L8     0.003502        4.401   \n",
       "20 2020-09-30 18:22:51      L8     0.000000        4.235   \n",
       "21 2020-12-03 18:22:54      L8     0.000000        4.724   \n",
       "22 2020-12-19 18:22:53      L8     0.000000        4.938   \n",
       "23 2021-01-04 18:22:48      L8     0.000000        4.964   \n",
       "24 2021-01-20 18:22:41      L8     0.000000        5.149   \n",
       "25 2021-02-05 18:22:40      L8     0.000000        4.352   \n",
       "26 2021-02-21 18:22:35      L8     0.000000        4.232   \n",
       "27 2021-03-09 18:22:27      L8     0.060021        5.644   \n",
       "28 2021-06-13 18:22:22      L8     0.010056        4.434   \n",
       "29 2021-10-19 18:22:59      L8     0.000000        4.356   \n",
       "30 2021-11-23 18:25:01      L9     0.001055        4.860   \n",
       "31 2021-12-22 18:22:51      L8     0.106271        5.356   \n",
       "32 2022-01-23 18:22:43      L8     0.000000        5.018   \n",
       "33 2022-02-16 18:22:44      L9     0.000000        4.984   \n",
       "34 2022-02-24 18:22:34      L8     0.000000        4.809   \n",
       "35 2022-03-04 18:22:34      L9     0.348253        6.277   \n",
       "36 2022-03-12 18:22:30      L8     0.000000        4.449   \n",
       "37 2022-04-13 18:22:23      L8     0.000000        4.154   \n",
       "38 2022-04-21 18:22:18      L9     0.035151        3.886   \n",
       "39 2022-06-24 18:22:26      L9     0.000000        4.793   \n",
       "40 2022-07-02 18:22:47      L8     0.000000        4.817   \n",
       "41 2022-08-11 18:22:43      L9     0.000000        4.334   \n",
       "42 2022-08-19 18:23:05      L8     0.019461        4.262   \n",
       "43 2022-08-27 18:22:47      L9     0.003008        4.178   \n",
       "44 2022-09-20 18:23:12      L8     0.004018        3.943   \n",
       "45 2022-10-22 18:23:08      L8     0.248255        5.138   \n",
       "46 2022-10-30 18:22:59      L9     0.020157        4.587   \n",
       "47 2022-11-15 18:23:01      L9     0.000000        4.828   \n",
       "48 2022-11-23 18:23:05      L8     0.000000        4.894   \n",
       "49 2022-12-09 18:23:05      L8     0.000000        5.371   \n",
       "50 2023-01-02 18:23:00      L9     0.059842        5.832   \n",
       "51 2023-01-18 18:22:52      L9     0.149705        5.798   \n",
       "52 2023-02-19 18:22:55      L9     0.000000        5.287   \n",
       "\n",
       "                                             geometry  \n",
       "0   MULTIPOINT (-117.46831 33.29341, -117.46822 33...  \n",
       "1   MULTIPOINT (-117.46822 33.29345, -117.46815 33...  \n",
       "2   MULTIPOINT (-117.46815 33.29345, -117.46805 33...  \n",
       "3   MULTIPOINT (-117.44858 33.26998, -117.44854 33...  \n",
       "4   MULTIPOINT (-117.46834 33.29332, -117.46831 33...  \n",
       "5   MULTIPOINT (-117.46209 33.28590, -117.46199 33...  \n",
       "6   MULTIPOINT (-117.46831 33.29335, -117.46828 33...  \n",
       "7   MULTIPOINT (-117.46832 33.29332, -117.46831 33...  \n",
       "8   MULTIPOINT (-117.46829 33.29345, -117.46817 33...  \n",
       "9   MULTIPOINT (-117.46154 33.28536, -117.46150 33...  \n",
       "10  MULTIPOINT (-117.46817 33.29345, -117.46815 33...  \n",
       "11  MULTIPOINT (-117.46824 33.29345, -117.46815 33...  \n",
       "12  MULTIPOINT (-117.46827 33.29345, -117.46815 33...  \n",
       "13  MULTIPOINT (-117.46829 33.29345, -117.46818 33...  \n",
       "14  MULTIPOINT (-117.46842 33.29331, -117.46833 33...  \n",
       "15  MULTIPOINT (-117.46831 33.29345, -117.46820 33...  \n",
       "16  MULTIPOINT (-117.43574 33.25393, -117.43573 33...  \n",
       "17  MULTIPOINT (-117.46831 33.29337, -117.46826 33...  \n",
       "18  MULTIPOINT (-117.46833 33.29332, -117.46831 33...  \n",
       "19  MULTIPOINT (-117.46829 33.29345, -117.46818 33...  \n",
       "20  MULTIPOINT (-117.46822 33.29345, -117.46815 33...  \n",
       "21  MULTIPOINT (-117.46824 33.29345, -117.46815 33...  \n",
       "22  MULTIPOINT (-117.46822 33.29345, -117.46815 33...  \n",
       "23  MULTIPOINT (-117.46824 33.29345, -117.46815 33...  \n",
       "24  MULTIPOINT (-117.46845 33.29331, -117.46836 33...  \n",
       "25  MULTIPOINT (-117.46831 33.29341, -117.46823 33...  \n",
       "26  MULTIPOINT (-117.46831 33.29343, -117.46820 33...  \n",
       "27  MULTIPOINT (-117.46572 33.29051, -117.46569 33...  \n",
       "28  MULTIPOINT (-117.45511 33.27808, -117.45503 33...  \n",
       "29  MULTIPOINT (-117.46817 33.29345, -117.46815 33...  \n",
       "30  MULTIPOINT (-117.46823 33.29345, -117.46815 33...  \n",
       "31  MULTIPOINT (-117.45486 33.27788, -117.45479 33...  \n",
       "32  MULTIPOINT (-117.46831 33.29334, -117.46829 33...  \n",
       "33  MULTIPOINT (-117.46811 33.29345, -117.46803 33...  \n",
       "34  MULTIPOINT (-117.46831 33.29332, -117.46831 33...  \n",
       "35  MULTIPOINT (-117.46608 33.29048, -117.46604 33...  \n",
       "36  MULTIPOINT (-117.46841 33.29332, -117.46831 33...  \n",
       "37  MULTIPOINT (-117.46829 33.29345, -117.46817 33...  \n",
       "38  MULTIPOINT (-117.44798 33.26931, -117.44789 33...  \n",
       "39  MULTIPOINT (-117.46831 33.29341, -117.46824 33...  \n",
       "40  MULTIPOINT (-117.46823 33.29345, -117.46815 33...  \n",
       "41  MULTIPOINT (-117.46812 33.29345, -117.46804 33...  \n",
       "42  MULTIPOINT (-117.45778 33.28118, -117.45777 33...  \n",
       "43  MULTIPOINT (-117.46284 33.28711, -117.46280 33...  \n",
       "44  MULTIPOINT (-117.46106 33.28482, -117.46102 33...  \n",
       "45  MULTIPOINT (-117.46821 33.29345, -117.46815 33...  \n",
       "46  MULTIPOINT (-117.44473 33.26540, -117.44467 33...  \n",
       "47  MULTIPOINT (-117.46825 33.29345, -117.46815 33...  \n",
       "48  MULTIPOINT (-117.46810 33.29345, -117.46802 33...  \n",
       "49  MULTIPOINT (-117.46810 33.29345, -117.46805 33...  \n",
       "50  MULTIPOINT (-117.46823 33.29345, -117.46815 33...  \n",
       "51  MULTIPOINT (-117.46223 33.28630, -117.46215 33...  \n",
       "52  MULTIPOINT (-117.46813 33.29345, -117.46805 33...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from coastseg.merge_utils import calculate_overlap, clip_gdfs,  read_first_geojson_file, convert_lines_to_multipoints,merge_and_average\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "result_gdf = gpd.GeoDataFrame( geometry=[], crs='epsg:4326')\n",
    "combined_gdf = gpd.GeoDataFrame( geometry=[], crs='epsg:4326')\n",
    "# calculate the overlapping regions between the ROIs\n",
    "overlap_gdf=calculate_overlap(roi_rows)\n",
    "\n",
    "# read all the extracted shorelines from the session locations\n",
    "gdfs = []\n",
    "for session_dir in session_locations:\n",
    "    # attempt to read the extracted shoreline files\n",
    "    es_gdf = read_first_geojson_file(session_dir,['extracted_shorelines_points.geojson', 'extracted_shorelines.geojson'])\n",
    "    es_gdf = convert_lines_to_multipoints(es_gdf)\n",
    "    es_gdf = es_gdf.to_crs('epsg:4326')\n",
    "    gdfs.append(es_gdf)\n",
    "print(f\"Read {len(gdfs)} extracted shorelines GeoDataFrames\")\n",
    "\n",
    "# clip the extracted shorelines to the overlapping regions\n",
    "clipped_shorelines_gdfs=clip_gdfs(gdfs, overlap_gdf)\n",
    "\n",
    "# sometimes there are not shorelines in the overlapping regions\n",
    "if overlap_gdf.empty or len(clipped_shorelines_gdfs) == 0:\n",
    "    print(\"No overlapping ROIs found. Sessions can be merged.\")\n",
    "    # merge the geodataframes on date and satname and average the cloud_cover and geoaccuracy for the merged rows\n",
    "\n",
    "    for gdf in gdfs:\n",
    "        if not gdf.crs:\n",
    "            gdf.set_crs(\"EPSG:4326\", inplace=True)\n",
    "        # result_gdf = pd.concat([gdf, result_gdf], ignore_index=True)\n",
    "        \n",
    "    # Perform a full outer join and average the numeric columns across all GeoDataFrames\n",
    "    result = reduce(merge_and_average, gdfs)\n",
    "\n",
    "    result.sort_values(by='date', inplace=True)\n",
    "    result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Combined {len(result)} rows from {len(gdfs)} GeoDataFrames\")\n",
    "print(f\"The following dataframe contains the combined extracted shorelines from all sessions.\\n Shorelines that were extracted on the same dates have been combined.\")\n",
    "\n",
    "\n",
    "combined_gdf = result\n",
    "combined_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Merged Extracted Shorelines to a JSON file\n",
    "- This will contains all the metadata for each extracted shoreline such as \n",
    "\n",
    "\n",
    "      1. cloud cover\n",
    "      2. date\n",
    "      3. satellite it was derived from \n",
    "      4. geoaccuracy\n",
    "- Filename: `extracted_shorelines_dict.json`\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping of dictionary keys to dataframe columns\n",
    "keymap ={'shorelines':'geometry',\n",
    "         'dates':'date',\n",
    "         'satname':'satname',\n",
    "         'cloud_cover':'cloud_cover',\n",
    "         'geoaccuracy':'geoaccuracy'}\n",
    "# shoreline dict should have keys: dates, satname, cloud_cover, geoaccuracy, shorelines\n",
    "shoreline_dict = dataframe_to_dict(combined_gdf,keymap)\n",
    "# save the extracted shoreline dictionary to json file\n",
    "to_file(shoreline_dict, os.path.join(merged_session_location, \"extracted_shorelines_dict.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shoreline_dict['shorelines'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Merged Extracted Shorelines to GeoJSON Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save extracted shorelines as a GeoJSON file\n",
    "es_line_path = os.path.join(merged_session_location, \"extracted_shorelines_lines.geojson\")\n",
    "es_pts_path = os.path.join(merged_session_location, \"extracted_shorelines_points.geojson\")\n",
    "\n",
    "es_lines_gdf = convert_multipoints_to_linestrings(combined_gdf)\n",
    "# save extracted shorelines as interpolated linestrings\n",
    "es_lines_gdf.to_file(es_line_path, driver='GeoJSON')\n",
    "\n",
    "\n",
    "points_gdf = convert_linestrings_to_multipoints(combined_gdf)\n",
    "points_gdf = stringify_datetime_columns(points_gdf)\n",
    "# Save extracted shorelines as mulitpoints GeoJSON file\n",
    "points_gdf.to_file(es_pts_path, driver='GeoJSON')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Find when the Transects and Shorelines intersect\n",
    "1. Loads the Transects for all the ROIs \n",
    "2. Get the shoreline dictionary we created earlier and read the shorelines from it\n",
    "3. Find where the shorelines and transects intersect\n",
    "4. Save the shoreline and transect intersections as a timeseries to a csv file\n",
    "5. Save the timeseries of intersections between the shoreline and a single tranesct to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. load transects for all ROIs\n",
    "transect_rows = merged_config[merged_config['type'] == 'transect']\n",
    "transects_dict = {row['id']: np.array(row[\"geometry\"].coords) for i, row in transect_rows.iterrows()}\n",
    "# 2. compute the intersection between the transects and the extracted shorelines\n",
    "cross_distance = SDS_transects.compute_intersection_QC(shoreline_dict, transects_dict, settings_transects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use coastseg.common to get the cross_distance_df\n",
    "transects_df = get_cross_distance_df(shoreline_dict,cross_distance)\n",
    "# save the transect shoreline intersections to csv timeseries file\n",
    "filepath = os.path.join(merged_session_location, \"transect_time_series.csv\")\n",
    "transects_df.to_csv(filepath, sep=\",\")\n",
    "transects_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the timeseries of intersections between the shoreline and a single tranesct to csv file\n",
    "create_csv_per_transect(merged_session_location,cross_distance,shoreline_dict,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidally Correct Shoreline Transect Intersections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Tide Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoaccuracy</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>satname</th>\n",
       "      <th>date</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>L8</td>\n",
       "      <td>2018-12-30 18:22:25</td>\n",
       "      <td>MULTIPOINT (0.00000 0.00000, 1.00000 1.00000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>L8</td>\n",
       "      <td>2018-01-30 19:22:25</td>\n",
       "      <td>MULTIPOINT (2.00000 2.00000, 3.00000 3.00000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>L8</td>\n",
       "      <td>2022-01-03 19:22:25</td>\n",
       "      <td>MULTIPOINT (4.00000 4.00000, 5.00000 5.00000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geoaccuracy  cloud_cover satname                date  \\\n",
       "0            1          0.1      L8 2018-12-30 18:22:25   \n",
       "1            2          0.2      L8 2018-01-30 19:22:25   \n",
       "2            3          0.3      L8 2022-01-03 19:22:25   \n",
       "\n",
       "                                        geometry  \n",
       "0  MULTIPOINT (0.00000 0.00000, 1.00000 1.00000)  \n",
       "1  MULTIPOINT (2.00000 2.00000, 3.00000 3.00000)  \n",
       "2  MULTIPOINT (4.00000 4.00000, 5.00000 5.00000)  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from coastseg.merge_utils import merge_geometries\n",
    "\n",
    "# create a list of geometries\n",
    "geometries = [\n",
    "    MultiPoint([(0, 0), (1, 1)]),\n",
    "    MultiPoint([(2, 2), (3, 3)]),\n",
    "    MultiPoint([(4, 4), (5, 5)]),\n",
    "]\n",
    "# create a dictionary with the other columns\n",
    "data = {\n",
    "    \"geoaccuracy\": [1, 2, 3],\n",
    "    \"cloud_cover\": [0.1, 0.2, 0.3],\n",
    "    \"satname\": [\"L8\", \"L8\", \"L8\"],\n",
    "    \"date\": [\n",
    "        pd.Timestamp(\"2018-12-30 18:22:25\"),\n",
    "        pd.Timestamp(\"2018-1-30 19:22:25\"),\n",
    "        pd.Timestamp(\"2022-01-03 19:22:25\"),\n",
    "    ],\n",
    "    \"geometry\": geometries,\n",
    "}\n",
    "# create a GeoDataFrame from the dictionary\n",
    "df = gpd.GeoDataFrame(data, geometry=\"geometry\", crs=\"epsg:4326\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoaccuracy</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>satname</th>\n",
       "      <th>date</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>L8</td>\n",
       "      <td>2018-12-30 18:22:25</td>\n",
       "      <td>MULTIPOINT (0.00000 0.00000, 1.00000 1.00000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>L8</td>\n",
       "      <td>2018-01-30 19:22:25</td>\n",
       "      <td>MULTIPOINT (2.00000 2.00000, 3.00000 3.00000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>L8</td>\n",
       "      <td>2022-01-03 19:22:25</td>\n",
       "      <td>MULTIPOINT (4.00000 4.00000, 5.00000 5.00000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geoaccuracy  cloud_cover satname                date  \\\n",
       "0            1          0.1      L8 2018-12-30 18:22:25   \n",
       "1            2          0.2      L8 2018-01-30 19:22:25   \n",
       "2            3          0.3      L8 2022-01-03 19:22:25   \n",
       "\n",
       "                                        geometry  \n",
       "0  MULTIPOINT (0.00000 0.00000, 1.00000 1.00000)  \n",
       "1  MULTIPOINT (2.00000 2.00000, 3.00000 3.00000)  \n",
       "2  MULTIPOINT (4.00000 4.00000, 5.00000 5.00000)  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = merge_geometries(df)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>geometry</th>\n",
       "      <th>geoaccuracy</th>\n",
       "      <th>satname</th>\n",
       "      <th>cloud_cover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-30 18:22:25</td>\n",
       "      <td>MULTIPOINT (-117.45892 33.28226, -118.45892 35...</td>\n",
       "      <td>5.088</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-28 05:12:28</td>\n",
       "      <td>MULTIPOINT (-117.45881 33.28239, -120.45892 40...</td>\n",
       "      <td>5.802</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-23 19:24:27</td>\n",
       "      <td>MULTIPOINT (-117.45875 33.28242)</td>\n",
       "      <td>6.596</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.263967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                           geometry  \\\n",
       "0 2018-12-30 18:22:25  MULTIPOINT (-117.45892 33.28226, -118.45892 35...   \n",
       "1 2019-01-28 05:12:28  MULTIPOINT (-117.45881 33.28239, -120.45892 40...   \n",
       "2 2020-05-23 19:24:27                   MULTIPOINT (-117.45875 33.28242)   \n",
       "\n",
       "   geoaccuracy satname  cloud_cover  \n",
       "0        5.088      L8     0.000000  \n",
       "1        5.802      L8     0.230000  \n",
       "2        6.596      L8     0.263967  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import MultiPoint, MultiLineString, LineString, Point\n",
    "\n",
    "data = {\n",
    "        \"date\": [\n",
    "            pd.Timestamp(\"2018-12-30 18:22:25\"),\n",
    "            pd.Timestamp(\"2019-1-28 05:12:28\"),\n",
    "            pd.Timestamp(\"2020-5-23 19:24:27\"),\n",
    "        ],\n",
    "        \"geometry\": [\n",
    "            MultiPoint([(-117.45892, 33.28226), (-118.45892, 35.28226)]),\n",
    "            MultiPoint([(-117.45881, 33.28239), (-120.45892, 40.28226)]),\n",
    "            MultiPoint([(-117.45875, 33.28242)]),\n",
    "        ],\n",
    "        \"geoaccuracy\": [\n",
    "            5.088,\n",
    "            5.802,\n",
    "            6.596,\n",
    "        ],\n",
    "        \"satname\": [\"L8\", \"L8\", \"L8\"],\n",
    "        \"cloud_cover\": [0.0, 0.23, 0.263967],\n",
    "    }\n",
    "extracted_gdf1 = gpd.GeoDataFrame(data, crs=\"epsg:4326\")\n",
    "extracted_gdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>geometry</th>\n",
       "      <th>geoaccuracy</th>\n",
       "      <th>satname</th>\n",
       "      <th>cloud_cover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-30 18:22:25</td>\n",
       "      <td>MULTIPOINT (-117.44480 33.26540)</td>\n",
       "      <td>5.088</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-28 05:12:28</td>\n",
       "      <td>MULTIPOINT (-117.45899 33.28226)</td>\n",
       "      <td>5.802</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-23 19:24:27</td>\n",
       "      <td>MULTIPOINT (-117.45896 33.28226)</td>\n",
       "      <td>6.596</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.263967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                          geometry  geoaccuracy satname  \\\n",
       "0 2018-12-30 18:22:25  MULTIPOINT (-117.44480 33.26540)        5.088      L8   \n",
       "1 2020-01-28 05:12:28  MULTIPOINT (-117.45899 33.28226)        5.802      L8   \n",
       "2 2020-05-23 19:24:27  MULTIPOINT (-117.45896 33.28226)        6.596      L8   \n",
       "\n",
       "   cloud_cover  \n",
       "0     0.000000  \n",
       "1     0.000000  \n",
       "2     0.263967  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the gdf shares pd.Timestamp('2018-12-30 18:22:25') and  pd.Timestamp('2020-5-23 19:24:27') with extracted_gdf1\n",
    "data = {\n",
    "    \"date\": [\n",
    "        pd.Timestamp(\"2018-12-30 18:22:25\"),\n",
    "        pd.Timestamp(\"2020-1-28 05:12:28\"),\n",
    "        pd.Timestamp(\"2020-5-23 19:24:27\"),\n",
    "    ],\n",
    "    \"geometry\": [\n",
    "        MultiPoint([(-117.44480, 33.26540)]),\n",
    "        MultiPoint([(-117.45899, 33.28226)]),\n",
    "        MultiPoint([(-117.45896, 33.28226)]),\n",
    "    ],\n",
    "    \"geoaccuracy\": [\n",
    "        5.088,\n",
    "        5.802,\n",
    "        6.596,\n",
    "    ],\n",
    "    \"satname\": [\"L8\", \"L8\", \"L8\"],\n",
    "    \"cloud_cover\": [0.0, 0.0, 0.263967],\n",
    "}\n",
    "extracted_gdf2 = gpd.GeoDataFrame(data, crs=\"epsg:4326\")\n",
    "extracted_gdf2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>geometry</th>\n",
       "      <th>geoaccuracy</th>\n",
       "      <th>satname</th>\n",
       "      <th>cloud_cover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-30 18:22:25</td>\n",
       "      <td>MULTIPOINT (-117.45896 33.28226)</td>\n",
       "      <td>5.088</td>\n",
       "      <td>L9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-28 05:12:28</td>\n",
       "      <td>MULTIPOINT (-117.45894 33.28226)</td>\n",
       "      <td>5.802</td>\n",
       "      <td>L9</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-23 19:24:27</td>\n",
       "      <td>MULTIPOINT (-117.45891 33.28232)</td>\n",
       "      <td>6.596</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.263967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                          geometry  geoaccuracy satname  \\\n",
       "0 2015-12-30 18:22:25  MULTIPOINT (-117.45896 33.28226)        5.088      L9   \n",
       "1 2019-01-28 05:12:28  MULTIPOINT (-117.45894 33.28226)        5.802      L9   \n",
       "2 2020-05-23 19:24:27  MULTIPOINT (-117.45891 33.28232)        6.596      L8   \n",
       "\n",
       "   cloud_cover  \n",
       "0     0.000000  \n",
       "1     0.100000  \n",
       "2     0.263967  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"date\": [\n",
    "        pd.Timestamp(\"2015-12-30 18:22:25\"),\n",
    "        pd.Timestamp(\"2019-1-28 05:12:28\"),\n",
    "        pd.Timestamp(\"2020-5-23 19:24:27\"),\n",
    "    ],\n",
    "    \"geometry\": [\n",
    "        MultiPoint([(-117.45896, 33.28226)]),\n",
    "        MultiPoint([(-117.45894, 33.28226)]),\n",
    "        MultiPoint([(-117.45891, 33.28232)]),\n",
    "    ],\n",
    "    \"geoaccuracy\": [\n",
    "        5.088,\n",
    "        5.802,\n",
    "        6.596,\n",
    "    ],\n",
    "    \"satname\": [\"L9\", \"L9\", \"L8\"],\n",
    "    \"cloud_cover\": [0.0, 0.1, 0.263967],\n",
    "}\n",
    "extracted_gdf3 = gpd.GeoDataFrame(data, crs=\"epsg:4326\")\n",
    "extracted_gdf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>geometry_x</th>\n",
       "      <th>geoaccuracy_x</th>\n",
       "      <th>satname_x</th>\n",
       "      <th>cloud_cover_x</th>\n",
       "      <th>geometry_y</th>\n",
       "      <th>geoaccuracy_y</th>\n",
       "      <th>satname_y</th>\n",
       "      <th>cloud_cover_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-30 18:22:25</td>\n",
       "      <td>MULTIPOINT (-117.45892 33.28226, -118.45892 35...</td>\n",
       "      <td>5.088</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MULTIPOINT (-117.44480 33.26540)</td>\n",
       "      <td>5.088</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-23 19:24:27</td>\n",
       "      <td>MULTIPOINT (-117.45875 33.28242)</td>\n",
       "      <td>6.596</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.263967</td>\n",
       "      <td>MULTIPOINT (-117.45896 33.28226)</td>\n",
       "      <td>6.596</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.263967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-28 05:12:28</td>\n",
       "      <td>MULTIPOINT (-117.45881 33.28239, -120.45892 40...</td>\n",
       "      <td>5.802</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>MULTIPOINT (-117.45894 33.28226)</td>\n",
       "      <td>5.802</td>\n",
       "      <td>L9</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-23 19:24:27</td>\n",
       "      <td>MULTIPOINT (-117.45875 33.28242)</td>\n",
       "      <td>6.596</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.263967</td>\n",
       "      <td>MULTIPOINT (-117.45891 33.28232)</td>\n",
       "      <td>6.596</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.263967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-23 19:24:27</td>\n",
       "      <td>MULTIPOINT (-117.45896 33.28226)</td>\n",
       "      <td>6.596</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.263967</td>\n",
       "      <td>MULTIPOINT (-117.45891 33.28232)</td>\n",
       "      <td>6.596</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.263967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                         geometry_x  \\\n",
       "0 2018-12-30 18:22:25  MULTIPOINT (-117.45892 33.28226, -118.45892 35...   \n",
       "1 2020-05-23 19:24:27                   MULTIPOINT (-117.45875 33.28242)   \n",
       "0 2019-01-28 05:12:28  MULTIPOINT (-117.45881 33.28239, -120.45892 40...   \n",
       "1 2020-05-23 19:24:27                   MULTIPOINT (-117.45875 33.28242)   \n",
       "0 2020-05-23 19:24:27                   MULTIPOINT (-117.45896 33.28226)   \n",
       "\n",
       "   geoaccuracy_x satname_x  cloud_cover_x                        geometry_y  \\\n",
       "0          5.088        L8       0.000000  MULTIPOINT (-117.44480 33.26540)   \n",
       "1          6.596        L8       0.263967  MULTIPOINT (-117.45896 33.28226)   \n",
       "0          5.802        L8       0.230000  MULTIPOINT (-117.45894 33.28226)   \n",
       "1          6.596        L8       0.263967  MULTIPOINT (-117.45891 33.28232)   \n",
       "0          6.596        L8       0.263967  MULTIPOINT (-117.45891 33.28232)   \n",
       "\n",
       "   geoaccuracy_y satname_y  cloud_cover_y  \n",
       "0          5.088        L8       0.000000  \n",
       "1          6.596        L8       0.263967  \n",
       "0          5.802        L9       0.100000  \n",
       "1          6.596        L8       0.263967  \n",
       "0          6.596        L8       0.263967  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Put all dataframes in a list\n",
    "dfs = [extracted_gdf1, extracted_gdf2, extracted_gdf3]\n",
    "\n",
    "# Initialize an empty list to store the merged dataframes\n",
    "merged_dfs = []\n",
    "\n",
    "# Loop over all combinations of 2 dataframes\n",
    "for df_a, df_b in combinations(dfs, 2):\n",
    "    # Perform an 'inner' merge and append the result to the list\n",
    "    merged_dfs.append(df_a.merge(df_b, on='date', how='inner'))\n",
    "\n",
    "# Concatenate all the merged dataframes\n",
    "final_df = pd.concat(merged_dfs)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>satname</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>geoaccuracy</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-30 18:22:25</td>\n",
       "      <td>L9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.088</td>\n",
       "      <td>POINT (-117.45896 33.28226)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-30 18:22:25</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.088</td>\n",
       "      <td>MULTIPOINT (-118.45892 35.28226, -117.45892 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-28 05:12:28</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>5.802</td>\n",
       "      <td>MULTIPOINT (-120.45892 40.28226, -117.45881 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-28 05:12:28</td>\n",
       "      <td>L9</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>5.802</td>\n",
       "      <td>POINT (-117.45894 33.28226)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-28 05:12:28</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.802</td>\n",
       "      <td>POINT (-117.45899 33.28226)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-05-23 19:24:27</td>\n",
       "      <td>L8</td>\n",
       "      <td>0.263967</td>\n",
       "      <td>6.596</td>\n",
       "      <td>MULTIPOINT (-117.45896 33.28226, -117.45891 33...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date satname  cloud_cover  geoaccuracy  \\\n",
       "0 2015-12-30 18:22:25      L9     0.000000        5.088   \n",
       "1 2018-12-30 18:22:25      L8     0.000000        5.088   \n",
       "2 2019-01-28 05:12:28      L8     0.230000        5.802   \n",
       "3 2019-01-28 05:12:28      L9     0.100000        5.802   \n",
       "4 2020-01-28 05:12:28      L8     0.000000        5.802   \n",
       "5 2020-05-23 19:24:27      L8     0.263967        6.596   \n",
       "\n",
       "                                            geometry  \n",
       "0                        POINT (-117.45896 33.28226)  \n",
       "1  MULTIPOINT (-118.45892 35.28226, -117.45892 33...  \n",
       "2  MULTIPOINT (-120.45892 40.28226, -117.45881 33...  \n",
       "3                        POINT (-117.45894 33.28226)  \n",
       "4                        POINT (-117.45899 33.28226)  \n",
       "5  MULTIPOINT (-117.45896 33.28226, -117.45891 33...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Optional, Union\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.ops import unary_union\n",
    "from coastseg.merge_utils import merge_geometries\n",
    "\n",
    "\n",
    "def merge_and_average(df1: gpd.GeoDataFrame, df2: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    # Perform a full outer join\n",
    "    merged = pd.merge(df1, df2, on=['satname', 'date'], how='outer', suffixes=('_df1', '_df2'))\n",
    "\n",
    "    # Identify numeric columns from both dataframes\n",
    "    numeric_columns_df1 = df1.select_dtypes(include='number').columns\n",
    "    numeric_columns_df2 = df2.select_dtypes(include='number').columns\n",
    "    common_numeric_columns = set(numeric_columns_df1).intersection(numeric_columns_df2)\n",
    "\n",
    "    # Average the numeric columns\n",
    "    for column in common_numeric_columns:\n",
    "        merged[column] = merged[[f'{column}_df1', f'{column}_df2']].mean(axis=1)\n",
    "\n",
    "    # Drop the original numeric columns\n",
    "    merged.drop(columns=[f'{column}_df1' for column in common_numeric_columns] + [f'{column}_df2' for column in common_numeric_columns], inplace=True)\n",
    "\n",
    "    # Merge geometries\n",
    "    geometry_columns = [col for col in merged.columns if 'geometry' in col]\n",
    "    merged = merge_geometries(merged, columns=geometry_columns)\n",
    "\n",
    "    return merged\n",
    "\n",
    "# List of GeoDataFrames\n",
    "gdfs = [extracted_gdf1, extracted_gdf2, extracted_gdf3]\n",
    "\n",
    "# Perform a full outer join and average the numeric columns across all GeoDataFrames\n",
    "result = reduce(merge_and_average, gdfs)\n",
    "\n",
    "result.sort_values(by='date', inplace=True)\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "assert len(result) == 6\n",
    "assert result[['date', 'satname']].duplicated().sum() == 0, \"The combination of 'date' and 'satname' is not unique.\"\n",
    "# assert np.all(result['cloud_cover'] == [0.0, 0.115, 0.263967, 0.0, 0.0, 0.1])\n",
    "\n",
    "result \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2015-12-30 18:22:25\n",
       "1   2018-12-30 18:22:25\n",
       "2   2019-01-28 05:12:28\n",
       "3   2019-01-28 05:12:28\n",
       "4   2020-01-28 05:12:28\n",
       "5   2020-05-23 19:24:27\n",
       "Name: date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import MultiPoint, MultiLineString, LineString, Point\n",
    "\n",
    "data = {\n",
    "        \"date\": [\n",
    "            pd.Timestamp(\"2018-12-30 18:22:25\"),\n",
    "        ],\n",
    "        \"geometry\": [\n",
    "            MultiPoint([(-110.45892, 30.28226), (-110.45892, 31.28226)]),\n",
    "        ],\n",
    "        \"geoaccuracy\": [\n",
    "            5.088,\n",
    "        ],\n",
    "        \"satname\": [ \"S2\", ],\n",
    "        \"cloud_cover\": [ 0.23,],\n",
    "    }\n",
    "extracted_gdf1 = gpd.GeoDataFrame(data, crs=\"epsg:4326\")\n",
    "extracted_gdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the gdf shares pd.Timestamp('2018-12-30 18:22:25') and  pd.Timestamp('2020-5-23 19:24:27') with extracted_gdf1\n",
    "data = {\n",
    "    \"date\": [\n",
    "        pd.Timestamp(\"2015-12-30 18:22:25\"),\n",
    "        pd.Timestamp(\"2020-1-28 05:12:28\"),\n",
    "    ],\n",
    "    \"geometry\": [\n",
    "        MultiPoint([(-117.44480, 33.26540)]),\n",
    "        MultiPoint([(-117.45899, 33.28226)]),\n",
    "    ],\n",
    "    \"geoaccuracy\": [\n",
    "        5.088,\n",
    "        6.02,\n",
    "    ],\n",
    "    \"satname\": [\"L8\", \"L8\", ],\n",
    "    \"cloud_cover\": [0.0,0.263967],\n",
    "}\n",
    "extracted_gdf2 = gpd.GeoDataFrame(data, crs=\"epsg:4326\")\n",
    "extracted_gdf2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"date\": [\n",
    "        pd.Timestamp(\"2023-12-30 18:22:25\"),\n",
    "        pd.Timestamp(\"1998-4-28 05:12:28\"),\n",
    "        pd.Timestamp(\"2001-8-23 19:24:27\"),\n",
    "    ],\n",
    "    \"geometry\": [\n",
    "        MultiPoint([(-117.45896, 33.28226)]),\n",
    "        MultiPoint([(-117.45894, 33.28226)]),\n",
    "        MultiPoint([(-117.45891, 33.28232)]),\n",
    "    ],\n",
    "    \"geoaccuracy\": [\n",
    "        5.088,\n",
    "        5.802,\n",
    "        6.596,\n",
    "    ],\n",
    "    \"satname\": [\"L9\", \"L9\", \"L8\"],\n",
    "    \"cloud_cover\": [0.0, 0.1, 0.263967],\n",
    "}\n",
    "extracted_gdf3 = gpd.GeoDataFrame(data, crs=\"epsg:4326\")\n",
    "extracted_gdf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of GeoDataFrames\n",
    "gdfs = [extracted_gdf1, extracted_gdf2, extracted_gdf3]\n",
    "# Perform a full outer join and average the numeric columns across all GeoDataFrames\n",
    "result = reduce(merge_and_average, gdfs)\n",
    "# this merge should not have any common dates and should contain 1+2+3 = 6 rows\n",
    "result.sort_values(by='date', inplace=True)\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of GeoDataFrames\n",
    "gdfs = [extracted_gdf1, extracted_gdf2, extracted_gdf3]\n",
    "# Perform a full outer join and average the numeric columns across all GeoDataFrames\n",
    "result = reduce(merge_and_average, gdfs)\n",
    "# this merge should not have any common dates and should contain 1+2+3 = 6 rows\n",
    "result.sort_values(by='date', inplace=True)\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatenate the 'geoaccuracy' values from all GeoDataFrames\n",
    "concated_gdf = pd.concat([gdf for gdf in gdfs])\n",
    "\n",
    "# Check if the values in expected_geoaccuracy are present in the 'geoaccuracy' column of the result DataFrame\n",
    "assert concated_gdf['geoaccuracy'].isin(result['geoaccuracy']).all()\n",
    "\n",
    "assert len(result) == 6\n",
    "# Check if the values in expected_geoaccuracy are present in the 'geoaccuracy' column of the result DataFrame\n",
    "assert concated_gdf['geoaccuracy'].isin(result['geoaccuracy']).all()\n",
    "assert concated_gdf['cloud_cover'].isin(result['cloud_cover']).all()\n",
    "assert concated_gdf['date'].isin(result['date']).all()\n",
    "assert concated_gdf['satname'].isin(result['satname']).all()\n",
    "# this test should not have merged any geometries because they were all on different dates\n",
    "assert concated_gdf['date'].isin(result['date']).all()\n",
    "\n",
    "result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Concatenate the geoaccuracy values from all dataframes\n",
    "expected_geoaccuracy = np.concatenate([extracted_gdf1['geoaccuracy'].values, extracted_gdf2['geoaccuracy'].values, extracted_gdf3['geoaccuracy'].values])\n",
    "\n",
    "# Convert expected_geoaccuracy to a pandas Series\n",
    "expected_geoaccuracy_series = pd.Series(expected_geoaccuracy)\n",
    "\n",
    "# Check if the values in expected_geoaccuracy_series are present in the 'geoaccuracy' column of the result DataFrame\n",
    "assert expected_geoaccuracy_series.isin(result['geoaccuracy']).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of GeoDataFrames\n",
    "gdfs = [extracted_gdf1, extracted_gdf2, extracted_gdf3]\n",
    "\n",
    "# Concatenate the 'geoaccuracy' values from all GeoDataFrames\n",
    "expected_geoaccuracy = pd.concat([gdf['geoaccuracy'] for gdf in gdfs])\n",
    "\n",
    "# Check if the values in expected_geoaccuracy are present in the 'geoaccuracy' column of the result DataFrame\n",
    "assert expected_geoaccuracy.isin(result['geoaccuracy']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of GeoDataFrames\n",
    "gdfs = [extracted_gdf1, extracted_gdf2, extracted_gdf3]\n",
    "\n",
    "# Concatenate the 'geoaccuracy' values from all GeoDataFrames\n",
    "concated_gdf = pd.concat([gdf for gdf in gdfs])\n",
    "\n",
    "# Check if the values in expected_geoaccuracy are present in the 'geoaccuracy' column of the result DataFrame\n",
    "assert concated_gdf['geoaccuracy'].isin(result['geoaccuracy']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = extracted_gdf1['geoaccuracy'].isin(result['geoaccuracy'])\n",
    "assert len(extracted_gdf1[mask]) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = extracted_gdf1['geoaccuracy'].isin(result['geoaccuracy'])\n",
    "assert len(extracted_gdf1[mask]) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"date\": [\n",
    "\n",
    "    ],\n",
    "    \"geometry\": [\n",
    "\n",
    "    ],\n",
    "    \"geoaccuracy\": [\n",
    "\n",
    "    ],\n",
    "    \"satname\": [],\n",
    "    \"cloud_cover\": [],\n",
    "}\n",
    "empty_gdf = gpd.GeoDataFrame(data, crs=\"epsg:4326\")\n",
    "empty_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the gdf shares pd.Timestamp('2018-12-30 18:22:25') and  pd.Timestamp('2020-5-23 19:24:27') with extracted_gdf1\n",
    "data = {\n",
    "    \"date\": [\n",
    "        pd.Timestamp(\"2015-12-30 18:22:25\"),\n",
    "        pd.Timestamp(\"2020-1-28 05:12:28\"),\n",
    "    ],\n",
    "    \"geometry\": [\n",
    "        MultiPoint([(-117.44480, 33.26540)]),\n",
    "        MultiPoint([(-117.45899, 33.28226)]),\n",
    "    ],\n",
    "    \"geoaccuracy\": [\n",
    "        5.088,\n",
    "        6.02,\n",
    "    ],\n",
    "    \"satname\": [\"L8\", \"L8\", ],\n",
    "    \"cloud_cover\": [0.0,0.263967],\n",
    "}\n",
    "extracted_gdf2 = gpd.GeoDataFrame(data, crs=\"epsg:4326\")\n",
    "extracted_gdf2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coastseg.merge_utils import convert_lines_to_multipoints\n",
    "\n",
    "# List of GeoDataFrames\n",
    "gdfs = [empty_gdf, extracted_gdf2]\n",
    "# Perform a full outer join and average the numeric columns across all GeoDataFrames\n",
    "result = reduce(merge_and_average, gdfs)\n",
    "# this merge should not have any common dates and should contain 1+2+3 = 6 rows\n",
    "result.sort_values(by='date', inplace=True)\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "assert len(result) == len(extracted_gdf2)\n",
    "assert result['date'].equals(extracted_gdf2['date'])\n",
    "assert result['satname'].equals(extracted_gdf2['satname'])\n",
    "assert result['cloud_cover'].equals(extracted_gdf2['cloud_cover'])\n",
    "assert result['geoaccuracy'].equals(extracted_gdf2['geoaccuracy'])\n",
    "# convert the result geometry to multipoint\n",
    "new_result = convert_lines_to_multipoints(result)\n",
    "assert new_result['geometry'].equals(extracted_gdf2['geometry'])\n",
    "\n",
    "result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(result) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>satname</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>sat1</td>\n",
       "      <td>MULTIPOINT (0.00000 0.00000, 1.00000 1.00000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date satname                                       geometry\n",
       "0  2022-01-01    sat1  MULTIPOINT (0.00000 0.00000, 1.00000 1.00000)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from coastseg.merge_utils import merge_geometries\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "data = {\n",
    "            \"date\": [\"2022-01-01\",],\n",
    "            \"satname\": [\"sat1\",],\n",
    "            \"geometry_df1\": [\n",
    "                Point(0, 0),\n",
    "            ],\n",
    "            \"geometry\": [Point(1, 1)],\n",
    "        }\n",
    "gdf = gpd.GeoDataFrame(data)\n",
    "result = merge_geometries(gdf)\n",
    "result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = None\n",
    "merged_gdf = gdf\n",
    "if columns is None:\n",
    "    columns = [col for col in merged_gdf.columns if \"geometry\" in col]\n",
    "else:\n",
    "    columns = [col for col in columns if col in merged_gdf.columns]\n",
    "    \n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.ops import unary_union\n",
    "\n",
    "merged_gdf = gdf\n",
    "merged_gdf[\"geometry\"] = merged_gdf[columns].apply(\n",
    "    lambda row: unary_union(row.tolist()), axis=1\n",
    ")\n",
    "merged_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns:\n",
    "    if col in merged_gdf.columns and col != \"geometry\":\n",
    "        print(col)\n",
    "        merged_gdf = merged_gdf.drop(columns=col)\n",
    "merged_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "            \"date\": [\"2022-01-01\",],\n",
    "            \"satname\": [\"sat1\",],\n",
    "            \"geometry_df1\": [\n",
    "                Point(0, 0),\n",
    "            ],\n",
    "            \"geometry_df2\": [Point(1, 1)],\n",
    "        }\n",
    "gdf = gpd.GeoDataFrame(data)\n",
    "result = merge_geometries(gdf)\n",
    "result "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
